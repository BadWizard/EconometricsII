---
title: "problemFour"
author: "Daniel"
date: "April 16, 2015"
output: word_document
---

# Problem 17.6
Consider a family saving function for the population of all families in the United States:  
sav = β0 + β1inc + hhsize + β3educ + β4age + u,

where hhsize is household size, educ is years of education of the household head, and age is age of the household head. Assume that E(u|inc,hhsize,educ,age) =  0.

## Part (i)
Suppose that the sample includes only families whose head is over 25 years old. If we use OLS on such a sample, do we get unbiased estimators of the βj? Explain.

The estimates from OLS will be unbiased because the sample chosen is based on an exogenous regressor. The population regression function for the family saving function is the same as the regression function in the sample with heads older than 25 years. 

## Part (ii)
Now, suppose our sample includes only married couples without children. Can we estimate all of the parameters in the saving equation? Which ones can we estimate?  

No, we cannot estimate all the parameters. For example, since there is no variation in hhsize in the subpopulation, we would not be able to estimate β2. However we can estimate the intercept in the subpopulation becomes β0 + 2β2.  

Assuming there is variation in inc, educ, and age among married people without children, we can still estimate β1, β3, and β4.

## Part (iii)
Suppose we exclude from our sample families that save more than $25,000 per year. Does OLS produce consistent estimators of the βj?

OLS does not produce consistent estimators. This is because we would be selecting the sample on the basis of the dependent variable. A much better option would to use a truncated regression model. 

# Problem 17.7
Suppose you are hired by a university to study the factors that determine whether students admitted to the university actually come to the university. You are given a large random sample of students who were admitted the previous year. You have information on whether each student chose to attend, high school performance, family income, financial aid offered, race, and geographic variables. Someone says to you, “Any analysis of that data will lead to biased results because it is not a random sample of all college applicants, but only those who apply to this university.” What do you think of this criticism?

Since the research is on this specific univeristy, I think it is appropriate to specify a model for this kind of data that consist of only applicants for this university. So I do not think that there is a sample selection problem.
 
However, if the pool of applicants changes in the near future, then there is a sample selection problem because the current students that apply may be different from students that may apply in the future. 

# Problem C17.7
Use the MROZ.RAW data for this exercise.

## Part (i)
Using the 428 women who were in the workforce, estimate the return to education by OLS including exper, exper2, nwifeinc, age, kidslt6, and kidsge6 as explanatory variables. Report your estimate on educ and its standard error.
```{r}
# Read the data into R
library(haven)
w_data <- read_dta("MROZ.dta")

# Estimate the return to education by OLS
fit_lm <- lm(lwage ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6, data = w_data)

# Tabulate the model results
library(stargazer)
stargazer(fit_lm, type = "text", title = "Return to Education for Working Women")
```

The coefficient and standard error on educ are 0.1 and 0.015 respectively. 

## Part (ii)
Now, estimate the return to education by Heckit, where all exogenous variables show up in the second-stage regression. In other words, the regression is log(wage) on educ, exper, exper2, nwifeinc, age, kidslt6, kidsge6, and estimated lambda. Compare the estimated return to education and its standard error to that from part (i).
```{r}
# Estimate a model by Heckit method
library(sampleSelection)

fit_hkt <- heckit(selection = inlf ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6, 
                  outcome = lwage ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6,
                  method = "2step", data = w_data) 

# Display the results
summary(fit_hkt)
```

The estimated return to education is 11.9%, (Coefficient = 0.1187 and Standard Error = 0.034). The estimated return to education is larger than without the Heckit corrections, but the Heckit standard error is more than two times larger. 

## Part (iii)
Using only the 428 observations for working women, regress estimated lambda on educ, exper, exper2, nwifeinc, age, kidslt6, and kidsge6. How big is the R-squared? How does this help explain your findings from part (ii)? (Hint: Think multicollinearity.)
```{r}
# Obtain the inverse mills ration as lambda 
myProbit <- glm(inlf ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6, 
                family = binomial(link = "probit" ), data = w_data)
w_data$IMR <- invMillsRatio(myProbit)$IMR1 

# Regress estimated lambda
fit_lm2 <- lm(IMR ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6, data = w_data)

# Show the model results
stargazer(fit_lm2, type = "text", title = "Model Results")
```

The model produces a high R squared value of 0.968. This shows that there is multicollinearity among the regressors in the second stage regression, which led to the large standard errors in part (ii).




















