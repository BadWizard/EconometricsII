---
title: "problemThree"
author: "Daniel"
date: "April 8, 2015"
output: word_document
---

# Problem 9.4
The following equation explains weekly hours of television viewing by a child in terms of the child's age, mother's education, father's education, and number of siblings:

tvhours = ??0 + ??1age + ??2age2 + ??3motheduc + ??4fatheduc + ??5sibs + u.

We are worried that tvhours is measured with error in our survey. Let tvhours denote the reported hours of television viewing per week.

## Part (i)
What do the classical errors-in-variables (CEV) assumptions require in this application?

The CEV assumptions requires that the measurement error have zero mean and be uncorrelated with tvhours and each explanatory variable in the equation.


## Part (ii)
Do you think the CEV assumptions are likely to hold? Explain.

I don't think the CEV assumptions are ikely to hold. This is because tvhours depends directly on the explanatory variables. 

# Problem 15.2
Suppose that you wish to estimate the effect of class attendance on student performance, as in Example 6.3. A basic model is  

stndfnl = ??0 + ??1atndrte + ??2priGPA + ??3ACT + u,

where the variables are defined as in Chapter 6.

## Part (i)
Let dist be the distance from the students' living quarters to the lecture hall. Do you think dist is uncorrelated with u?

Yes, it's possible for distance and the error term to be uncorrelated. This is because classrooms are randomly assigned without consideration for where students live. 

## Part (ii)
Assuming that dist and u are uncorrelated, what other assumption must dist satisfy to be a valid IV for atndrte?

The other assumption is that distance must be partially correlated with the varibale "atndrte". 

## Part (iii)
Suppose, as in equation (6.18), we add the interaction term priGPA.atndrte:

stndfnl = ??0 + ??1atndrte + ??2priGPA + ??3ACT + ??4priGPA.atndrte + u.

If atndrte is correlated with u, then, in general, so is priGPA.atndrte. What might be a good IV for priGPA.atndrte?

A good IV for may be the interaction term between GPA and distance, priGPA???dist. 


# Problem 15.4
Suppose that, for a given state in the United States, you wish to use annual time series data to estimate the effect of the state-level minimum wage on the employment of those 18 to 25 years old (EMP). A simple model is

gEMPt = b0 + b1gMINt + b2gPOPt + b3gGSPt + b4gGDPt + ut,

where MINt is the minimum wage, in real dollars, POPt is the population from 18 to 25 years old, GSPt is gross state product, and GDPt is U.S. gross domestic product. The g prefix indicates the growth rate from year t - 1 to year t, which would typically be approximated by the difference in the logs.

## Part (i)
If we are worried that the state chooses its minimum wage partly based on unobserved (to us) factors that affect youth employment, what is the problem with OLS estimation?

This means that the Minimum wage will be correlated with the unobserved error term thereby making estimates from OLS to be biased and inconsistent. 

## Part (ii)
Let USMINt be the U.S. minimum wage, which is also measured in real terms. Do you think gUSMINt is uncorrelated with ut?

The U.S. minimum wage may be uncorrelated with the error term because the Gross Domestic Factor controls for the overall performance of the US economy.

## Part (iii)
By law, any state's minimum wage must be at least as large as the U.S. minimum. Explain why this makes gUSMINt a potential IV candidate for gMINt.

This is because the State minimum wage is correlated with the US minimum wage, that is, as the national wage increases so must the State wage. It is also uncorrelated with the disturbance term.


# Problem 15.6

## Part (i)
In the model with one endogenous explanatory variable, one exogenous explanatory variable, and one extra exogenous variable, take the reduced form for y2 (15.26), and plug it into the structural equation (15.22). This gives the reduced form for y1:

y1 = ??0 + ??1z1 + ??2z2 + v1.

Find the ??j in terms of the ??j  and the ??j.

y1 = ??0 + ??1(??0 + ??1z1 + ??2z2 + v2) + ??2z1 + u1
y1 = (??0 + ??1??0) + (??1??1 + ??2)z1 + ??1??2z2 + u1 + ??1v2, hence
   
??0 = ??0 + ??1??0, 
??1 = ??1??1 + ??2, and 
??2 = ??1??2.

## Part (ii)
Find the reduced form error, v1, in terms of u1, v2, and the parameters.

v1 = u1 + ??1v2. 

## Part (iii)
How would you consistently estimate the ??j?

v1 has zero mean and is uncorrelated with z1 and z2, which means that OLS consistently estimates the ??j.


# Problem C15.3
Use the data in CARD.RAW for this exercise.  

## Part (i)
The equation we estimated in Example 15.4 can be written as  

log(wage) = ??0 + ??1educ + ??2exper + ... + u,

where the other explanatory variables are listed in Table 15.1. In order for IV to be consistent, the IV for educ, nearc4, must be uncorrelated with u. Could nearc4 be correlated with things in the error term, such as unobserved ability? Explain.  

It's possible for proximity to college to be correlated with things in the error term such as unobserrved ability. One could argue that the presence of a college can motivate an individual to work harder in school so that they can one day make to college themselves.


## Part (ii)
For a subsample of the men in the data set, an IQ score is available. Regress IQ on nearc4 to check whether average IQ scores vary by whether the man grew up near
a four-year college. What do you conclude?

```{r}
# read the data into R
library(haven)
card_data <- read_dta("CARD.dta")

# Regress IQ on nearc4
lm_model1 <- lm(iq~nearc4, data = card_data)

# Put the model in a tabular format
library(stargazer)
stargazer(lm_model1, type = "text", title = "Regression of IQ on Proximity to College")
```

The model shows that the predicted IQ is 2.6 points higher if the man grew up near a four-year college. This estimate is statistically significant at a 0.01 level of confidence.


## Part (iii)
Now, regress IQ on nearc4, smsa66, and the 1966 regional dummy variables
reg662, ... ,reg669. Are IQ and nearc4 related after the geographic dummy variables have been partialled out? Reconcile this with your findings from part (ii).

```{r}
# Regress IQ on nearc4, smsa66, and reg662, ... ,reg669.
lm_model2 <- lm(iq~nearc4 + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + reg669, data = card_data)

stargazer(lm_model2, type = "text", title = "Regression of IQ on More Variables")
```

The model shows that nearc4 is statistically insignificant. This means that proximity to a four-year college does not influence the IQ score, controling for region and environment while growing up. 


## Part (iv)
 From parts (ii) and (iii), what do you conclude about the importance of controlling for smsa66 and the 1966 regional dummies in the log(wage) equation?  

It is important because it allows control for differences in access to colleges that might also be correlated with ability. 


# Problem C15.5
Use the data in CARD.RAW for this exercise.

## Part (i)
In Table 15.1, the difference between the IV and OLS estimates of the return to education is economically important. Obtain the reduced form residuals, v2, from the reduced form regression educ on nearc4, exper, expersq, black, smsa, south, smsa66, reg662, ..., reg669 ---see Table15.1. Use these to test whether educ is exogenous; that is, determine if the difference between OLS and IV is statistically significant.

```{r}
# The reduced form is obtained as follows
lm_model3 <- lm(lwage ~ educ + nearc4 + exper + expersq + black + smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + reg669, data = card_data)

# Obtain the residuals
v_residuals <- resid(lm_model3)

# Add the residuals to the original equation
x <- card_data
lm_model4 <- lm(x$lwage ~ x$educ + x$nearc4 + x$exper + x$expersq + x$black + x$smsa + x$south + x$smsa66 + x$reg662 + x$reg663 + x$reg664 + x$reg665 + x$reg666 + x$reg667 + x$reg668 + x$reg669 + v_residuals)

# Display the model results
summary(lm_model4)
```

The coefficient on the residual is 1.0 with a t-statistic of 7. Hence the difference in the estimates of the return to education is statistically significant. 

## Part (ii)
Estimate the equation by 2SLS, adding nearc2 as an instrument. Does the coefficient on educ change much?
```{r}
# Estimate the equation by 2SLS
library(AER)

formula1 <- lwage ~ educ + nearc4 + exper + expersq + black + smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + reg669

inst1 <- ~ nearc2 + nearc4 + exper + expersq + black + smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + reg669

fit_iv1 <- ivreg(formula1, inst = inst1, data = card_data)
summary(fit_iv1)
```

The 2SLS estimate of the coefficient on educ is now 0.29 with a standard error = 0.18. This estimate is bigger than the previous one. 

## Part (iii)
Test the single overidentifying restriction from part (ii).



# Problem C15.8
Use the data in 401KSUBS.RAW for this exercise. 

## Part (i)
Estimate the equation by OLS and discuss the estimated effect of p401k.
```{r}
# Read the data into R
ksubs_data <- read_dta("401KSUBS.dta")

# Fit a linear model by OLS
fit_lm <- lm(pira ~ p401k + inc + incsq + age, data = ksubs_data)

# Tabulate the model results
stargazer(fit_lm, type = "text", title = "Model Results using OLS")
```

The model shows that having a 401(k) plan increases the probability of having an individual retirement account by 0.052.   

## Part (ii)
For the purposes of estimating the ceteris paribus tradeoff between participation in two different types of retirement savings plans, what might be a problem with ordinary least squares?

The model in part(i) does not account for the fact that different people may have different saving preferences. People who are savers tend to have both a 401(k) plan as well as an IRA. This makes the error term positively correlated with p401k. 


## Part (iii)
The variable e401k is a binary variable equal to one if a worker is eligible to participate in a 401(k) plan. Explain what is required for e401k to be a valid IV for p401k. Do these assumptions seem reasonable?  

Condition 1: e401k has to be correlated with p401k. 
Condition 2: e401k has to be uncorrelated with the unobserved residual error. 

## Part (iv)
Estimate the reduced form for p401k and verify that e401k has significant partial correlation with p401k. Since the reduced form is also a linear probability model, use a heteroskedasticity-robust standard error.
```{r}
# Estimate the reduced form 
fit_lm2 <- lm(p401k ~ e401k + inc + incsq + age + agesq, data = ksubs_data)

# obtain the model results using a heteroskedasticity-robust standard error
coeftest(fit_lm2, vcov = vcovHC) 
```

Eligibility for 401k is statistically significant correlated with the propbability of having a 401k at a 0.01 level of confidence.

## Part (v)
Now, estimate the structural equation by IV and compare the estimate of ??1 with the OLS estimate. Again, you should obtain heteroskedasticity-robust standard errors.
```{r}
# Estimate the structural equation by IV
formula2 <- pira ~ p401k + inc + incsq + age + agesq
inst2 <- ~ e401k + inc + incsq + age + agesq
fit_iv2 <- ivreg(formula2, inst = inst2, data = ksubs_data)
stargazer(fit_iv2, type = "text")
```

The IV estimate for p401k is less than the OLS estimate.

## Part (vi)
Test the null hypothesis that p401k is in fact exogenous, using a heteroskedasticityrobust
test.
```{r}
# Obtain the reduced form residuals from part (iv)
v_residuals2 <- resid(fit_lm2)

# Add the residuals to the structural equation and run OLS
fit_lm3 <- lm(ksubs_data$pira ~ ksubs_data$p401k + ksubs_data$inc + ksubs_data$incsq + ksubs_data$age + ksubs_data$agesq + v_residuals2)

# obtain the model results using a heteroskedasticity-robust test
coeftest(fit_lm3, vcov = vcovHC) 
```

The model shows that the residual is statistically significant with t value of 3.9. This means that p401k is endogenous.

# Problem C15.9
The purpose of this exercise is to compare the estimates and standard errors obtained by correctly using 2SLS with those obtained using inappropriate procedures. Use the data file WAGE2.RAW.

## Part (i)
Use a 2SLS routine to estimate the equation  

log(wage) = ??0 + ??1educ + ??2exper + ??3tenure + ??4black + u,  

where sibs is the IV for educ. Report the results in the usual form.
```{r}
# Read the data into R
wage_data <- read_dta("WAGE2.dta")

# Use 2SLS
formula3 <- lwage ~ educ + exper + tenure + black
inst3 <- ~sibs + exper + tenure + black
fit_iv3 <- ivreg(formula3, inst = inst3, data = wage_data)
stargazer(fit_iv3, type = "text")
```


## Part (ii)
Now, manually carry out 2SLS. That is, first regress educ on sibs, exper, tenure, and black and obtain the fitted values. Then, run the second stage regression log(wage) on educ estimate, exper, tenure, and black. Verify that the estimate ?? coefficients are identical to those obtained from part (i), but that the standard errors are somewhat different. The standard errors obtained from the second stage regression when manually carrying out 2SLS are generally inappropriate.
```{r}
# First regression
fit_lm4 <- lm(educ ~ sibs + exper + tenure + black, data = wage_data)

# Obtain the fitted values
educ_fitted <- fitted(fit_lm4)

# Then run the second stage regression
fit_lm5 <- lm(wage_data$lwage ~ educ_fitted + wage_data$exper + wage_data$tenure + wage_data$black)

# Display the model results
stargazer(fit_lm5, type = "text")
```

The standard errors in part(i) and part(ii) are 0.034 and 0.035 respectively.

## Part (iii)
Now, use the following two-step procedure, which generally yields inconsistent
parameter estimates of the ??j, and not just inconsistent standard errors. In step one, regress educ on sibs only and obtain the fitted values, say educ estimated. (Note that this is an incorrect first stage regression.) Then, in the second step, run the regression of log(wage) on educ_estimated, , experi
, tenure, and black. How does the estimate from this incorrect, two-step procedure compare with the correct 2SLS estimate of the return to education?

```{r}
# First regression
fit_lm6 <- lm(educ ~ sibs, data = wage_data)

# Obtain the fitted values
educ_fitted2 <- fitted(fit_lm6)

# Then run the second stage regression
fit_lm7 <- lm(wage_data$lwage ~ educ_fitted2 + wage_data$exper + wage_data$tenure + wage_data$black)

# Display the model results
stargazer(fit_lm7, type = "text")
```

The incorrent method shows a coefficient on 0.07 for estimated eduction. This is lower than the estimate from the correct method of 0.094.


# Problem C15.10
Use the data in HTV.RAW for this exercise.

## Part (i)
Run a simple OLS regression of log(wage) on educ. Without controlling for other
factors, what is the 95% confidence interval for the return to another year of
education?
```{r}
# Read the data into R
htv_data <- read_dta("HTV.dta")

# Run a simple OLS
fit_lm8 <- lm(lwage ~ educ, data = htv_data)
stargazer(fit_lm8, type = "text", ci = TRUE, ci.level = 0.95)
```

The 95% confidence interval is [0.088, 0.114].

## Part (ii)
The variable ctuit, in thousands of dollars, is the change in college tuition facing students from age 17 to age 18. Show that educ and ctuit are essentially uncorrelated. What does this say about ctuit as a possible IV for educ in a simple regression analysis?
```{r}
# show that educ and ctuit are uncorrelated
fit_lm9 <- lm(educ ~ ctuit, data = htv_data)
summary(fit_lm9)
```

The t-statistic of -0.59 is less than the critical t-value of 1.96.
We fail to reject the null hypothesis that the estimate for ctuit is zero.
We conclude that educ and ctuit are uncorrelated. This means that ctuit is not a good IV for educ. 

## Part (iii)
Now, add to the simple regression model in part (i) a quadratic in experience and a full set of regional dummy variables for current residence and residence at age 18. Also include the urban indicators for current and age 18 residences. What is the estimated return to a year of education?
```{r}
# Add more variables to the simple regression
fit_lm10 <- lm(lwage ~ educ + exper + expersq + ne + nc + west + ne18 + nc18 + west18 + urban + urban18, data = htv_data)
stargazer(fit_lm10, type = "text")
```

The estimated return to a year of education is 13.7%.

## Part (iv)
Again using ctuit as a potential IV for educ, estimate the reduced form for educ.
[Naturally, the reduced form for educ now includes the explanatory variables in
part (iii).] Show that ctuit is now statistically significant in the reduced form for educ.  
```{r}
# Use ctuit as a potential IV
fit_lm11 <- lm(educ ~ ctuit + exper + expersq + ne + nc + west + ne18 + nc18 + west18 + urban + urban18, data = htv_data)
stargazer(fit_lm11, type = "text")
```

Change in tuition is now statistically significant at 0.01 level of confidence. Hence an increase in tuition fees reduces eduction by 0.165.

## Part (v)
Estimate the model from part (iii) by IV, using ctuit as an IV for educ. How does
the confidence interval for the return to education compare with the OLS CI from
part (iii)?
```{r}
#Estimate using IV method
formula4 <- lwage ~ educ + exper + expersq + ne + nc + west + ne18 + nc18 + west18 + urban + urban18
inst4 <- ~ctuit + exper + expersq + ne + nc + west + ne18 + nc18 + west18 + urban + urban18
fit_iv4 <- ivreg(formula4, inst = inst4, data = htv_data)
stargazer(fit_iv4, type = "text", ci = TRUE, ci.level = 0.95)
```

The confidence interval in the IV method is [0.011, 0.489] which is wider than the one from OLS.

## Part (vi)
Do you think the IV procedure from part (v) is convincing?  

The IV estimate has a large standared error thereby showing that the IV procedure is not convincing. Infact ctuit was found not to correlated with eduction.

